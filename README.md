<h1 align="center">Tugas Besar 2 IF3270 Pembelajaran Mesin</h1>
<h2 align="center">Convolutional Neural Network dan Recurrent Neural Network ğŸ§ </h2>

<h3 align="center">CIFAR-10 Datasets Visualization (CNN)</h3>
<div align="center">
  <img src="./doc/CIFAR-10.png" alt="CIFAR-10 Datasets" width="600"/>
</div>

<h3 align="center">NusaX-Sentiment Datasets Visualization (RNN & LSTM)</h3>
<div align="center">
  <img src="./doc/NusaX-Sentiment.png" alt="CIFAR-10 Datasets" width="600"/>
</div>

## ï¸ğŸ–¥ï¸ Deskripsi Umum
Repositori ini dibuat untuk memenuhi Tugas Besar II mata kuliah IF3270 - Pembelajaran Mesin. Proyek ini bertujuan untuk memberikan pemahaman praktis dan mendalam mengenai implementasi arsitektur Convolutional Neural Network (CNN) untuk klasifikasi gambar (image classification) pada dataset CIFAR-10, serta berbagai jenis Recurrent Neural Network (Simple RNN dan LSTM) untuk klasifikasi teks (text classification) pada dataset NusaX-Sentiment.

Tugas ini mencakup dua aspek utama:
1. Melatih dan menganalisis model-model CNN, Simple RNN, dan LSTM menggunakan library Keras. Eksplorasi ini melibatkan investigasi pengaruh berbagai hyperparameter seperti jumlah layer, jumlah filter atau cell, ukuran filter, jenis pooling layer, dan arah pemrosesan RNN/LSTM terhadap kinerja model.
2. Mengimplementasikan fungsi forward propagation untuk ketiga arsitektur tersebut (CNN, Simple RNN, dan LSTM) dari awal (from scratch). Implementasi from scratch ini hanya diizinkan menggunakan library untuk komputasi matematis (seperti NumPy)  dan bertujuan untuk memahami secara fundamental mekanisme kerja internal neural network tersebut. Bobot untuk implementasi from scratch diambil dari model yang telah dilatih menggunakan Keras, dan hasilnya divalidasi dengan membandingkannya terhadap output dari Keras menggunakan metrik macro f1-score.

## ğŸƒâ€â™‚ï¸ How To Run The Program
Proyek ini melibatkan tiga arsitektur utama *neural network*: Convolutional Neural Network (CNN), Simple Recurrent Neural Network (Simple RNN), dan Long-Short Term Memory (LSTM). Setiap model memiliki kumpulan *script* sendiri untuk pra-pemrosesan data, pelatihan model Keras dan analisis *hyperparameter*, serta implementasi *forward propagation from scratch*.

### Requirements ğŸ› ï¸

1.  Pastikan Anda telah menginstal Python 3.x.
2.  Direkomendasikan untuk menggunakan *virtual environment* untuk mengelola dependensi.
3.  Instal *library* yang dibutuhkan. Berdasarkan laporan Anda, *library* utama yang digunakan antara lain:
    ```bash
    pip install tensorflow numpy matplotlib scikit-learn pandas
    ```

### Project Directory ğŸ“
Proyek ini disusun sebagai berikut:
```
IF3270_Tubes2_62
â”œâ”€â”€ README.md
â”œâ”€â”€ doc
â”‚   â”œâ”€â”€ IF3270_Tubes2_62.pdf
â”‚   â”œâ”€â”€ CIFAR-10.png
â”‚   â””â”€â”€ NusaX-Sentiment.png
â””â”€â”€ src
    â”œâ”€â”€ cnn
    â”‚   â”œâ”€â”€ __pycache__
    â”‚   â”‚   â”œâ”€â”€ config.cpython-311.pyc
    â”‚   â”‚   â”œâ”€â”€ data_preprocessing.cpython-311.pyc
    â”‚   â”‚   â”œâ”€â”€ from_scratch.cpython-311.pyc
    â”‚   â”‚   â””â”€â”€ train.cpython-311.pyc
    â”‚   â”œâ”€â”€ checkpoints
    â”‚   â”‚   â”œâ”€â”€ 1_layers.weights.h5
    â”‚   â”‚   â”œâ”€â”€ 2_layers.weights.h5
    â”‚   â”‚   â”œâ”€â”€ 3_layers.weights.h5
    â”‚   â”‚   â”œâ”€â”€ 4_layers.weights.h5
    â”‚   â”‚   â”œâ”€â”€ average_pooling.weights.h5
    â”‚   â”‚   â”œâ”€â”€ basic_cnn.weights.h5
    â”‚   â”‚   â”œâ”€â”€ filters_16_32_64.weights.h5
    â”‚   â”‚   â”œâ”€â”€ filters_32_64_128.weights.h5
    â”‚   â”‚   â”œâ”€â”€ filters_64_128_256.weights.h5
    â”‚   â”‚   â”œâ”€â”€ kernels_3x3x3.weights.h5
    â”‚   â”‚   â”œâ”€â”€ kernels_3x4x5.weights.h5
    â”‚   â”‚   â”œâ”€â”€ kernels_4x3x3.weights.h5
    â”‚   â”‚   â””â”€â”€ max_pooling.weights.h5
    â”‚   â”œâ”€â”€ config.py
    â”‚   â”œâ”€â”€ data_preprocessing.py
    â”‚   â”œâ”€â”€ experiment_results
    â”‚   â”‚   â”œâ”€â”€ conv_layers_experiment_results.csv
    â”‚   â”‚   â”œâ”€â”€ filter_numbers_experiment_results.csv
    â”‚   â”‚   â”œâ”€â”€ kernel_sizes_experiment_results.csv
    â”‚   â”‚   â””â”€â”€ pooling_types_experiment_results.csv
    â”‚   â”œâ”€â”€ from_scratch.py
    â”‚   â”œâ”€â”€ main_cnn.ipynb
    â”‚   â”œâ”€â”€ model.py
    â”‚   â”œâ”€â”€ models
    â”‚   â”‚   â”œâ”€â”€ cnn_1_layers.keras
    â”‚   â”‚   â”œâ”€â”€ cnn_2_layers.keras
    â”‚   â”‚   â”œâ”€â”€ cnn_3_layers.keras
    â”‚   â”‚   â”œâ”€â”€ cnn_average_pooling.keras
    â”‚   â”‚   â”œâ”€â”€ cnn_filters_16_32_64.keras
    â”‚   â”‚   â”œâ”€â”€ cnn_filters_32_64_128.keras
    â”‚   â”‚   â”œâ”€â”€ cnn_filters_64_128_256.keras
    â”‚   â”‚   â”œâ”€â”€ cnn_kernels_3x3x3.keras
    â”‚   â”‚   â”œâ”€â”€ cnn_kernels_3x4x5.keras
    â”‚   â”‚   â”œâ”€â”€ cnn_kernels_4x3x3.keras
    â”‚   â”‚   â””â”€â”€ cnn_max_pooling.keras
    â”‚   â”œâ”€â”€ results
    â”‚   â””â”€â”€ train.py
    â”œâ”€â”€ lstm
    â”‚   â”œâ”€â”€ checkpoints
    â”‚   â”‚   â”œâ”€â”€ baseline_lstm_model.weights.h5
    â”‚   â”‚   â”œâ”€â”€ lstm_bidirectional_lstm.weights.h5
    â”‚   â”‚   â”œâ”€â”€ lstm_layers_1.weights.h5
    â”‚   â”‚   â”œâ”€â”€ lstm_layers_2.weights.h5
    â”‚   â”‚   â”œâ”€â”€ lstm_layers_3.weights.h5
    â”‚   â”‚   â”œâ”€â”€ lstm_unidirectional_lstm.weights.h5
    â”‚   â”‚   â”œâ”€â”€ lstm_units_128.weights.h5
    â”‚   â”‚   â”œâ”€â”€ lstm_units_32.weights.h5
    â”‚   â”‚   â”œâ”€â”€ lstm_units_64.weights.h5
    â”‚   â”‚   â””â”€â”€ optimal_lstm_l1_u32_bi.weights.h5
    â”‚   â”œâ”€â”€ config.py
    â”‚   â”œâ”€â”€ data
    â”‚   â”‚   â”œâ”€â”€ test.csv
    â”‚   â”‚   â”œâ”€â”€ train.csv
    â”‚   â”‚   â””â”€â”€ valid.csv
    â”‚   â”œâ”€â”€ data_preprocessing.py
    â”‚   â”œâ”€â”€ experiment_results_lstm
    â”‚   â”‚   â”œâ”€â”€ lstm_bidirectional_results.csv
    â”‚   â”‚   â”œâ”€â”€ lstm_layer_count_results.csv
    â”‚   â”‚   â”œâ”€â”€ lstm_unit_count_results.csv
    â”‚   â”‚   â””â”€â”€ lstm_variation_summary.csv
    â”‚   â”œâ”€â”€ from_scratch_lstm.py
    â”‚   â”œâ”€â”€ main_lstm.ipynb
    â”‚   â”œâ”€â”€ model.py
    â”‚   â”œâ”€â”€ models
    â”‚   â”‚   â”œâ”€â”€ baseline_lstm_model_full_model.keras
    â”‚   â”‚   â”œâ”€â”€ baseline_lstm_model_vectorizer.keras
    â”‚   â”‚   â”œâ”€â”€ lstm_bidirectional_lstm_full_model.keras
    â”‚   â”‚   â”œâ”€â”€ lstm_bidirectional_lstm_vectorizer.keras
    â”‚   â”‚   â”œâ”€â”€ lstm_layers_1_full_model.keras
    â”‚   â”‚   â”œâ”€â”€ lstm_layers_1_vectorizer.keras
    â”‚   â”‚   â”œâ”€â”€ lstm_layers_2_full_model.keras
    â”‚   â”‚   â”œâ”€â”€ lstm_layers_2_vectorizer.keras
    â”‚   â”‚   â”œâ”€â”€ lstm_layers_3_full_model.keras
    â”‚   â”‚   â”œâ”€â”€ lstm_layers_3_vectorizer.keras
    â”‚   â”‚   â”œâ”€â”€ lstm_unidirectional_lstm_full_model.keras
    â”‚   â”‚   â”œâ”€â”€ lstm_unidirectional_lstm_vectorizer.keras
    â”‚   â”‚   â”œâ”€â”€ lstm_units_128_full_model.keras
    â”‚   â”‚   â”œâ”€â”€ lstm_units_128_vectorizer.keras
    â”‚   â”‚   â”œâ”€â”€ lstm_units_32_full_model.keras
    â”‚   â”‚   â”œâ”€â”€ lstm_units_32_vectorizer.keras
    â”‚   â”‚   â”œâ”€â”€ lstm_units_64_full_model.keras
    â”‚   â”‚   â”œâ”€â”€ lstm_units_64_vectorizer.keras
    â”‚   â”‚   â”œâ”€â”€ optimal_lstm_l1_u32_bi_full_model.keras
    â”‚   â”‚   â””â”€â”€ optimal_lstm_l1_u32_bi_vectorizer.keras
    â”‚   â””â”€â”€ train.py
    â””â”€â”€ simplernn
        â”œâ”€â”€ checkpoints
        â”‚   â”œâ”€â”€ baseline_model.weights.h5
        â”‚   â”œâ”€â”€ optimal_rnn_l1_u96_bi.weights.h5
        â”‚   â”œâ”€â”€ rnn_bidirectional.weights.h5
        â”‚   â”œâ”€â”€ rnn_layers_1.weights.h5
        â”‚   â”œâ”€â”€ rnn_layers_2.weights.h5
        â”‚   â”œâ”€â”€ rnn_layers_3.weights.h5
        â”‚   â”œâ”€â”€ rnn_unidirectional.weights.h5
        â”‚   â”œâ”€â”€ rnn_units_24.weights.h5
        â”‚   â”œâ”€â”€ rnn_units_48.weights.h5
        â”‚   â””â”€â”€ rnn_units_96.weights.h5
        â”œâ”€â”€ config.py
        â”œâ”€â”€ data
        â”‚   â”œâ”€â”€ test.csv
        â”‚   â”œâ”€â”€ train.csv
        â”‚   â””â”€â”€ valid.csv
        â”œâ”€â”€ data_preprocessing.py
        â”œâ”€â”€ experiment_results
        â”‚   â”œâ”€â”€ bidirectional_results.csv
        â”‚   â”œâ”€â”€ layer_count_results.csv
        â”‚   â”œâ”€â”€ unit_count_results.csv
        â”‚   â””â”€â”€ variation_summary.csv
        â”œâ”€â”€ from_scratch.py
        â”œâ”€â”€ main_rnn.ipynb
        â”œâ”€â”€ model.py
        â”œâ”€â”€ models
        â”‚   â”œâ”€â”€ baseline_model_full_model.keras
        â”‚   â”œâ”€â”€ baseline_model_vectorizer.keras
        â”‚   â”œâ”€â”€ optimal_rnn_l1_u96_bi_full_model.keras
        â”‚   â”œâ”€â”€ optimal_rnn_l1_u96_bi_vectorizer.keras
        â”‚   â”œâ”€â”€ rnn_bidirectional_full_model.keras
        â”‚   â”œâ”€â”€ rnn_bidirectional_vectorizer.keras
        â”‚   â”œâ”€â”€ rnn_layers_1_full_model.keras
        â”‚   â”œâ”€â”€ rnn_layers_1_vectorizer.keras
        â”‚   â”œâ”€â”€ rnn_layers_2_full_model.keras
        â”‚   â”œâ”€â”€ rnn_layers_2_vectorizer.keras
        â”‚   â”œâ”€â”€ rnn_layers_3_full_model.keras
        â”‚   â”œâ”€â”€ rnn_layers_3_vectorizer.keras
        â”‚   â”œâ”€â”€ rnn_unidirectional_full_model.keras
        â”‚   â”œâ”€â”€ rnn_unidirectional_vectorizer.keras
        â”‚   â”œâ”€â”€ rnn_units_24_full_model.keras
        â”‚   â”œâ”€â”€ rnn_units_24_vectorizer.keras
        â”‚   â”œâ”€â”€ rnn_units_48_full_model.keras
        â”‚   â”œâ”€â”€ rnn_units_48_vectorizer.keras
        â”‚   â”œâ”€â”€ rnn_units_96_full_model.keras
        â”‚   â””â”€â”€ rnn_units_96_vectorizer.keras
        â””â”€â”€ train.py
```

### Running Experiment âš™ï¸

Untuk setiap model (CNN, Simple RNN, LSTM), cara utama untuk menjalankan eksperimen, melatih model Keras, dan menguji implementasi *from scratch* adalah melalui Jupyter Notebook masing-masing:
* `src/cnn/main_cnn.ipynb`
* `src/simplernn/main_rnn.ipynb`
* `src/lstm/main_lstm.ipynb`

**Alur Kerja Umum dalam Setiap Notebook:**

1.  **Navigasi ke direktori `src/<tipe_model>/`.**
2.  **Luncurkan Jupyter Notebook:**
    ```bash
    jupyter notebook main_<tipe_model>.ipynb
    ```
3.  **Ikuti sel-sel dalam notebook.** Notebook biasanya disusun untuk:
    * Mengimpor *library* dan modul yang diperlukan (misalnya, `config.py`, `model.py`, `train.py`, `data_preprocessing.py`, `from_scratch.py`).
    * Memuat dan melakukan pra-pemrosesan data (misalnya, CIFAR-10 untuk CNN, NusaX-Sentiment untuk RNN/LSTM).
        * Untuk CNN, ini termasuk membagi *training set* CIFAR-10 menjadi *training set* baru dan *validation set*.
        * Untuk RNN/LSTM, ini melibatkan proses *tokenization* menggunakan `TextVectorization` dan membuat sekuens *embedding*.
    * **Pelatihan Model Keras dan Analisis *Hyperparameter*:**
        * Mendefinisikan berbagai konfigurasi model (variasi jumlah *layer*, *filter/cell*, ukuran *kernel*, tipe *pooling*, arah pemrosesan) sesuai dengan "Spesifikasi Tugas Besar 2".
        * Menggunakan fungsi `create_<tipe_model>_model` dari `<tipe_model>/model.py` untuk membangun model Keras.
        * Melatih model menggunakan fungsi `train_and_evaluate_model` (atau serupa) dari `<tipe_model>/train.py`.
        * *Callback* seperti `ModelCheckpoint`, `EarlyStopping`, dan `ReduceLROnPlateau` akan digunakan selama pelatihan.
        * Menganalisis hasil: Membandingkan F1-*score*, grafik *training/validation loss*, dan menarik kesimpulan mengenai pengaruh *hyperparameter*.
        * Bobot model Keras terbaik atau yang representatif akan disimpan (misalnya, di direktori `checkpoints/` atau `models/`). Model Keras penuh dan *vectorizer* (untuk RNN/LSTM) juga disimpan.
    * **Implementasi dan Validasi *Forward Propagation From Scratch*:**
        * Memuat model Keras yang telah dilatih beserta bobotnya (dan *vectorizer* untuk RNN/LSTM).
        * Membuat instansiasi kelas model *from scratch* (misalnya, `CNNFromScratch`, `SimpleRNNFromScratch`, `LSTMFromScratch`) dari file `from_scratch.py` atau `from_scratch_lstm.py` masing-masing. Kelas-kelas ini akan memuat bobot Keras.
        * Melakukan prediksi pada *test set* menggunakan metode `predict` dari model Keras dan metode `forward` (atau `predict`) kustom dari model *from scratch*.
        * Membandingkan output:
            * *Macro f1-score* untuk keduanya.
            * Waktu prediksi.
            * Mean Absolute Error (MAE) antara probabilitas prediksi.
            * *Classification report* dan *confusion matrix*.

**Contoh: Menjalankan bagian CNN (langkah-langkah konseptual dalam `main_cnn.ipynb`)**

```python
# (Di dalam main_cnn.ipynb)

# 1. Impor modul yang diperlukan dari src.cnn
from config import ES_PATIENCE, LR_FACTOR # ... dan konfigurasi lainnya
from model import create_cnn_model
from train import train_and_evaluate_model, plot_combined_comparison
from data_preprocessing import load_cifar10_data
from from_scratch import CNNFromScratch, run_from_scratch_comparison 

# 2. Muat dan lakukan pra-pemrosesan data CIFAR-10
(x_train, y_train), (x_val, y_val), (x_test, y_test), class_names = load_cifar10_data() 

# 3. Pelatihan Model Keras & Analisis Hyperparameter
# Contoh: Eksperimen dengan jumlah layer konvolusi
# (Loop melalui jumlah layer, filter, ukuran kernel, tipe pooling yang berbeda sesuai spesifikasi)
# Untuk konfigurasi spesifik:
num_conv_layers = 2
filters = [32, 64]
kernels = [3, 3]
pooling = 'max'
model_name = f"cnn_{num_conv_layers}layers_{pooling}"

keras_cnn_model = create_cnn_model(
    conv_layers=num_conv_layers,
    filters_per_layer=filters,
    kernel_sizes=kernels,
    pooling_type=pooling
)
keras_cnn_model.summary()

trained_model, history, test_f1 = train_and_evaluate_model(
    keras_cnn_model,
    x_train, y_train, x_val, y_val, x_test, y_test,
    model_name=model_name,
    epochs=10 # Atau dari config
)
# ... (plotting, penyimpanan hasil untuk eksperimen ini) ...

# (Setelah menemukan model yang baik atau untuk model representatif)
# Asumsikan 'checkpoints/best_cnn_model.weights.h5' atau 'models/best_cnn_model_full.keras' disimpan

# 4. Validasi Forward Propagation From Scratch
# Path ke model Keras yang disimpan (pastikan model ini telah dilatih dan disimpan)
saved_keras_model_path = "models/best_cnn_model_full.keras" # Atau path yang sesuai

# Jalankan perbandingan
# Fungsi ini akan memuat model Keras, menginisialisasi CNNFromScratch,
# menjalankan prediksi, dan mencetak metrik perbandingan.
run_from_scratch_comparison(model_path=saved_keras_model_path)
```

## ğŸ§‘â€ğŸ­Pembagian Pekerjaan
<table border="1">
  <thead>
    <tr>
      <th>NIM</th>
      <th>Nama</th>
      <th>Pekerjaan</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>13522124</td>
      <td>Aland Mulia Pratama</td>
      <td>Mengimplementasikan CNN (Convolutional Neural Network) yang mencakup pembuatan file konfigurasi, preprocessing data, model, train, dan juga implementasi forward propagation from scratch. Mengerjakan laporan Deskripsi Persoalan, Implementasi CNN, Pengujian CNN, serta Daftar Pustaka.</td>
    </tr>
    <tr>
      <td>13522132</td>
      <td>Hafizh Hananta Akbari</td>
      <td>Tidak Mengerjakan Sama Sekali</td>
    </tr>
    <tr>
      <td>13522135</td>
      <td>Christian Justin Hendrawan</td>
      <td>Mengimplementasikan Simple RNN dan LSTM yang mencakup pembuatan file konfigurasi, preprocessing, model, train, dan implementasi from scratch. Mengerjakan laporan implementasi dan hasil pengujian Simple RNN dan LSTM, Kesimpulan & Saran, serta merapihkan format laporan.</td>
    </tr>
  </tbody>
</table>
